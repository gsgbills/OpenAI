{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions and Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai, os, glob, pandas as pd, numpy as np\n",
    "from typing import List\n",
    "import logging\n",
    "logging.basicConfig(filename='qa.log', encoding='utf-8', level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key ='ENTER KEY HERE'\n",
    "# Directory path containing text files\n",
    "TEXTDIR = \"btext/\"\n",
    "#File name for saving embbedings\n",
    "EMBEDDINGSF = \"embeddings.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_text_to_df (dir: str) -> pd.core.frame.DataFrame:\n",
    "    \"\"\"Return contents of all text files in the directory dir removing new lines and extra spaces into dataframe\"\"\"\n",
    "\n",
    "    text_files = glob.glob(os.path.join(TEXTDIR, \"*.txt\"))\n",
    "\n",
    "    # Read all text files into a list of (file names, file_text) removing new_lines\n",
    "    all_text = []\n",
    "    for file in text_files:\n",
    "        with open(file, \"r\") as f:\n",
    "            file_text = f.read().replace('\\n', ' ').replace(\"\\\\n\", \" \").replace('  ', ' ')\n",
    "            all_text.append((file.split('/')[-1], file_text))\n",
    "    df = pd.DataFrame(all_text, columns = ['title', 'text'])\n",
    "    return (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_all_text_to_df (TEXTDIR)\n",
    "\n",
    "# If the df is bigger than, e.g., 100MB, then save a copy in a new file\n",
    "memory_usage = df.memory_usage(deep=True).sum() / 1024**2 # convert bytes to megabytes\n",
    "if memory_usage > 100 :\n",
    "        print(f\"Memory usage: {memory_usage:.2f} MB\")\n",
    "        df.to_csv('pdqana.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[tiktoken](https://pub.dev/documentation/tiktoken/latest/) a Byte pair encoding (BPE) tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "# Load the cl100k_base tokenizer which is designed to work with the ada-002 model\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "# Tokenize the text and save the number of tokens to a new column 'n_tokens'\n",
    "df['n_tokens'] = df.text.apply(lambda x: len(tokenizer.encode(x)))\n",
    "\n",
    "print(f\"The largest document has {df.n_tokens.max()} tokens, the shortest {df.n_tokens.min()}, the average has {int(df.n_tokens.mean())}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the distribution of the number of tokens per row using a histogram\n",
    "df.n_tokens.hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The current documents are too long for handling, so we need to split them into smaller documents.\n",
    "`split_text_into_chunks` tokenizes the input of a document `doc` into sentences using `nltk.sent_tokenize()` function and then creates `chunks` by concatenating sentences until the chunk size limit is reached. The resulting chunks are returned as a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# Check if the punkt tokenizer data files are present in the nltk data directory, else download them.\n",
    "if not os.path.exists(nltk.data.find('tokenizers/punkt')):   nltk.download('punkt')\n",
    "#else:   print('punkt tokenizer data files already present')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text_into_chunks(doc:str, max_tokens:int =500) -> List[str]:\n",
    "    \"\"\"Return a list of strings from text where each string has less than max_tokens\"\"\"\n",
    "    # Tokenize the string `text` into a list of sentences\n",
    "    sentences = nltk.sent_tokenize(doc)\n",
    "\n",
    "    # If there is only one sentence and it has less than `max_tokens` tokens, return it\n",
    "    if len(sentences) == 1 and len(sentences[0].split()) <= max_tokens: return sentences\n",
    "\n",
    "    chunks = []   # empty list to store the chunks\n",
    "    current_chunk = \"\"\n",
    "    try:\n",
    "        # Loop through the sentences, grouping them into chunks of up to max_tokens\n",
    "        for sentence in sentences:\n",
    "            if len(current_chunk.split()) + len(sentence.split()) <= max_tokens:\n",
    "                current_chunk += sentence + \" \"\n",
    "            else:\n",
    "                chunks.append(current_chunk.strip())\n",
    "                current_chunk = sentence + \" \"\n",
    "\n",
    "        # Add the last chunk\n",
    "        if len(current_chunk) > 0: \n",
    "            chunks.append(current_chunk.strip()) \n",
    "        return chunks\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error splitting text into chunks: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_shortened(df, max_tokens:int = 500) -> list:\n",
    "    # apply the split_text_into_chunks() function to each row\n",
    "    chunks = df.apply(lambda row: split_text_into_chunks(row['text'], max_tokens) \n",
    "                      if row['n_tokens'] > max_tokens else [row['text']], axis=1)\n",
    "\n",
    "    # Flatten the list of chunks and return it\n",
    "    return [chunk for sublist in chunks for chunk in sublist]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a shortened list in a new df, then apply `tokenizer.encode` and save the number of tokens in each row in a new `n_tokens` column. \n",
    "Notice that BPE `tokenizer.encode()` will generate more tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sh = create_shortened(df, max_tokens=400)\n",
    "df = pd.DataFrame(sh, columns = ['text'])\n",
    "df['n_tokens'] = df.text.apply(lambda x: len(tokenizer.encode(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The largest document has {df.n_tokens.max()} tokens, the shortest {df.n_tokens.min()}, the average has {int(df.n_tokens.mean())}.\")\n",
    "\n",
    "df.n_tokens.hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below generates embeddings for the text in each row of the `df.text` column, and stores them in a new column `'embeddings'`.\n",
    "It uses the `apply()` method of the `df.text` column to apply a `lambda` function that takes `x`, (each row in the column). `openai.Embedding.create()` generates embeddings for a given input text, `x` using `'text-embedding-ada-002'`, a specific LM engine. \n",
    "`['data'][0]['embedding']` is extracting the embedding data from the API response, which is a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time df['embeddings'] = df.text.apply(lambda x: openai.Embedding.create(input=x, engine='text-embedding-ada-002')['data'][0]['embedding'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save and retrieve the embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if we read back the embeddings from a stored file we need to convert the string representations to the proper types.\n",
    "The built-in `eval()` function converts the string representation of a list or array to an actual list or array object. \n",
    "Then `np.array()` converts each list object to a NumPy array object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(EMBEDDINGSF)\n",
    "df=pd.read_csv(EMBEDDINGSF, index_col=0)\n",
    "df['embeddings'] = df['embeddings'].apply(eval).apply(np.array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create context\n",
    "`create_context` for a given question by finding the most similar context from the dataframe `df` of precomputed embeddings and their corresponding texts. \n",
    "Arguments:\n",
    "- `question`: a string representing the question for which the context is being created.\n",
    "- `df`: a pandas dataframe containing precomputed embeddings and their corresponding texts.\n",
    "- `max_len=1800`: an integer representing the maximum length of the context that can be returned.\n",
    "- `size='ada'`: a string representing the size of the language model used to compute embeddings.\n",
    "\n",
    "It first computes embeddings for the input question using the [text-embedding-ada-002](https://openai.com/blog/new-and-improved-embedding-model) engine, and then computes the distances between the question embeddings and the embeddings of the contexts in the dataframe `df` using the cosine distance metric.\n",
    "It then sorts `df` by the distances in ascending order and adds the text of the contexts to the `returns` list until the length of the concatenated texts exceeds the `max_len` limit. The function concatenates the texts in the `returns` list using the string `\"\\n\\n###\\n\\n\"` as a delimiter and returns the resulting string as the final context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from openai.embeddings_utils import distances_from_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "distances_from_embeddings(query_embedding: List[float], embeddings: List[List[float]], distance_metric='cosine',) -> List[List]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[openai.Embedding.create](https://platform.openai.com/docs/api-reference/embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_context(df, question:str = None,  max_len:int =1800, size:str =\"ada\", separator:str =\"\\n\\n###\\n\\n\"):\n",
    "    \"\"\"\n",
    "    Create a context for a question by finding the most similar context from the dataframe df\n",
    "    \"\"\"\n",
    "    # Get the embeddings for the question\n",
    "    try:\n",
    "        q_embeddings = openai.Embedding.create(input=question, engine=f'text-embedding-{size}-002')['data'][0]['embedding']\n",
    "    except Exception as e:  print(e)\n",
    "\n",
    "    # Get the distances from the embeddings\n",
    "    df['distances'] = distances_from_embeddings(q_embeddings, df['embeddings'].values)\n",
    "\n",
    "    # Sort by distance and add the text to the context until the context is too long\n",
    "    context_len = 0\n",
    "    context = [row[\"text\"] for i, row in df.sort_values('distances', ascending=True).iterrows() \n",
    "               if (context_len := context_len + row['n_tokens'] + 4) <= max_len]\n",
    "\n",
    "    # Return the context\n",
    "    return separator.join(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer Question\n",
    "`answer_question()` uses `create_context()` to find the most similar context to a given question in a given dataframe (`df`). It then uses OpenAI's API to generate a text response to the question based on the context.\n",
    "Parameters:\n",
    "- `df`: the pandas dataframe containing the texts to search for the context.\n",
    "- `model`: the OpenAI model used for generating the response. Default is \"text-davinci-003\".\n",
    "- `question`: the question to be answered.\n",
    "- `max_len`: the maximum length of the context to be considered when searching for the most similar context. Default is 1800.\n",
    "- `size`: the size of the OpenAI API engine to use for embedding the question. Default is \"ada\".\n",
    "- `debug`: a boolean indicating whether to print the raw model response. Default is False.\n",
    "- `max_tokens`: the maximum number of tokens to generate in the response. Default is 150.\n",
    "- `stop_sequence`: a string sequence that indicates when the response should stop generating. Default is None.\n",
    "\n",
    "It first calls `create_context()` to find the most similar context to the question. If `debug`, it prints the raw context.\n",
    "It then generates a `response` using [openai.Completion.create](https://platform.openai.com/docs/api-reference/completions) by providing a prompt that includes the context and the question to be answered. It sets various parameters such as the maximum number of tokens to generate, and the model (default [text-davinci-003](https://help.openai.com/en/articles/6779149-how-do-text-davinci-002-and-text-davinci-003-differ)) to use. If an exception occurs during the generation of the response, an empty string is returned. Otherwise, the generated response text is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(df, model:str=\"text-davinci-003\", question:str=\"\", max_len:int=1800, size:str=\"ada\",\n",
    "    debug:bool=False, max_tokens:int=150, stop_sequence:str=None):\n",
    "    \"\"\"\n",
    "    Answer a question based on the most similar context from the dataframe texts\n",
    "    \"\"\"\n",
    "    context = create_context(df, question, max_len=max_len, size=size, )\n",
    "\n",
    "    # If debug, print the raw model response\n",
    "    if debug: print(f\"Context:\\n {context} \\n\\n\")\n",
    "\n",
    "    #Prompt includes the question and context\n",
    "    prompt=f\"Answer the question based on the context below, and if the question can't be answered based on the context, \\\n",
    "    say \\\"I don't know\\\"\\n\\nContext: {context}\\n\\n---\\n\\nQuestion: {question}\\nAnswer:\"\n",
    "  \n",
    "    params = {\"prompt\": prompt, \n",
    "              \"temperature\": 0, \n",
    "              \"max_tokens\":max_tokens, \n",
    "              \"top_p\":1, \n",
    "              \"frequency_penalty\":0,\n",
    "              \"presence_penalty\":0, \n",
    "              \"stop\":stop_sequence, \n",
    "              \"model\":model\n",
    "             }\n",
    "    try: # Create a completions using the prompt\n",
    "        response = openai.Completion.create(**params)\n",
    "        return response.choices[0].text.strip()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\"What is stable diffusion?\", \n",
    "             \"What is a Unet?\",\n",
    "             \"How do we find a value for bandwidth?\"\n",
    "            ]\n",
    "for q in questions:\n",
    "    a = answer_question(df, question=q)\n",
    "    print(f\"Question: {q}\\n Answer: {a} \\n\")\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_question(df, question='How are latents used in Stable Diffusion?', debug=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with open(\"text/quizzes.txt\", \"r\") as file:\n",
    "    # Read all the lines in the file and store them in a list\n",
    "    lines = file.readlines()\n",
    "\n",
    "print(f\"There are {len(lines)} questions to answer.\")\n",
    "\n",
    "dontknow = 0\n",
    "for i, q in enumerate(lines):\n",
    "    a = answer_question(df, question=q)\n",
    "    print(f\"Question {i}: {q} Answer {i}: {a} \\n\")\n",
    "    if (a==\"I don't know.\"): dontknow = dontknow + 1\n",
    "print (f\"It answered \\\"I dont know.\\\" to {(dontknow-1)*100/i} \\% of the questions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "05f34a34d73b71652304030c1097be3a5720ea2447153dd6542d145a26b73181"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
